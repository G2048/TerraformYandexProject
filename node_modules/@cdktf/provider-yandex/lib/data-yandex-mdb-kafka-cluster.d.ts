import { Construct } from 'constructs';
import * as cdktf from 'cdktf';
export interface DataYandexMdbKafkaClusterConfig extends cdktf.TerraformMetaArguments {
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#cluster_id DataYandexMdbKafkaCluster#cluster_id}
    */
    readonly clusterId?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#deletion_protection DataYandexMdbKafkaCluster#deletion_protection}
    */
    readonly deletionProtection?: boolean | cdktf.IResolvable;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#folder_id DataYandexMdbKafkaCluster#folder_id}
    */
    readonly folderId?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#id DataYandexMdbKafkaCluster#id}
    *
    * Please be aware that the id field is automatically added to all resources in Terraform providers using a Terraform provider SDK version below 2.
    * If you experience problems setting this value it might not be settable. Please take a look at the provider documentation to ensure it should be settable.
    */
    readonly id?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#name DataYandexMdbKafkaCluster#name}
    */
    readonly name?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#subnet_ids DataYandexMdbKafkaCluster#subnet_ids}
    */
    readonly subnetIds?: string[];
    /**
    * config block
    *
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#config DataYandexMdbKafkaCluster#config}
    */
    readonly config?: DataYandexMdbKafkaClusterConfigA;
    /**
    * topic block
    *
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#topic DataYandexMdbKafkaCluster#topic}
    */
    readonly topic?: DataYandexMdbKafkaClusterTopic[] | cdktf.IResolvable;
    /**
    * user block
    *
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#user DataYandexMdbKafkaCluster#user}
    */
    readonly user?: DataYandexMdbKafkaClusterUser[] | cdktf.IResolvable;
}
export interface DataYandexMdbKafkaClusterHost {
}
export declare function dataYandexMdbKafkaClusterHostToTerraform(struct?: DataYandexMdbKafkaClusterHost): any;
export declare class DataYandexMdbKafkaClusterHostOutputReference extends cdktf.ComplexObject {
    private isEmptyObject;
    /**
    * @param terraformResource The parent resource
    * @param terraformAttribute The attribute on the parent resource this class is referencing
    * @param complexObjectIndex the index of this item in the list
    * @param complexObjectIsFromSet whether the list is wrapping a set (will add tolist() to be able to access an item via an index)
    */
    constructor(terraformResource: cdktf.IInterpolatingParent, terraformAttribute: string, complexObjectIndex: number, complexObjectIsFromSet: boolean);
    get internalValue(): DataYandexMdbKafkaClusterHost | undefined;
    set internalValue(value: DataYandexMdbKafkaClusterHost | undefined);
    get assignPublicIp(): cdktf.IResolvable;
    get health(): string;
    get name(): string;
    get role(): string;
    get subnetId(): string;
    get zoneId(): string;
}
export declare class DataYandexMdbKafkaClusterHostList extends cdktf.ComplexList {
    protected terraformResource: cdktf.IInterpolatingParent;
    protected terraformAttribute: string;
    protected wrapsSet: boolean;
    /**
    * @param terraformResource The parent resource
    * @param terraformAttribute The attribute on the parent resource this class is referencing
    * @param wrapsSet whether the list is wrapping a set (will add tolist() to be able to access an item via an index)
    */
    constructor(terraformResource: cdktf.IInterpolatingParent, terraformAttribute: string, wrapsSet: boolean);
    /**
    * @param index the index of the item to return
    */
    get(index: number): DataYandexMdbKafkaClusterHostOutputReference;
}
export interface DataYandexMdbKafkaClusterMaintenanceWindow {
}
export declare function dataYandexMdbKafkaClusterMaintenanceWindowToTerraform(struct?: DataYandexMdbKafkaClusterMaintenanceWindow): any;
export declare class DataYandexMdbKafkaClusterMaintenanceWindowOutputReference extends cdktf.ComplexObject {
    private isEmptyObject;
    /**
    * @param terraformResource The parent resource
    * @param terraformAttribute The attribute on the parent resource this class is referencing
    * @param complexObjectIndex the index of this item in the list
    * @param complexObjectIsFromSet whether the list is wrapping a set (will add tolist() to be able to access an item via an index)
    */
    constructor(terraformResource: cdktf.IInterpolatingParent, terraformAttribute: string, complexObjectIndex: number, complexObjectIsFromSet: boolean);
    get internalValue(): DataYandexMdbKafkaClusterMaintenanceWindow | undefined;
    set internalValue(value: DataYandexMdbKafkaClusterMaintenanceWindow | undefined);
    get day(): string;
    get hour(): number;
    get type(): string;
}
export declare class DataYandexMdbKafkaClusterMaintenanceWindowList extends cdktf.ComplexList {
    protected terraformResource: cdktf.IInterpolatingParent;
    protected terraformAttribute: string;
    protected wrapsSet: boolean;
    /**
    * @param terraformResource The parent resource
    * @param terraformAttribute The attribute on the parent resource this class is referencing
    * @param wrapsSet whether the list is wrapping a set (will add tolist() to be able to access an item via an index)
    */
    constructor(terraformResource: cdktf.IInterpolatingParent, terraformAttribute: string, wrapsSet: boolean);
    /**
    * @param index the index of the item to return
    */
    get(index: number): DataYandexMdbKafkaClusterMaintenanceWindowOutputReference;
}
export interface DataYandexMdbKafkaClusterConfigKafkaKafkaConfig {
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#auto_create_topics_enable DataYandexMdbKafkaCluster#auto_create_topics_enable}
    */
    readonly autoCreateTopicsEnable?: boolean | cdktf.IResolvable;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#compression_type DataYandexMdbKafkaCluster#compression_type}
    */
    readonly compressionType?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#default_replication_factor DataYandexMdbKafkaCluster#default_replication_factor}
    */
    readonly defaultReplicationFactor?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#log_flush_interval_messages DataYandexMdbKafkaCluster#log_flush_interval_messages}
    */
    readonly logFlushIntervalMessages?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#log_flush_interval_ms DataYandexMdbKafkaCluster#log_flush_interval_ms}
    */
    readonly logFlushIntervalMs?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#log_flush_scheduler_interval_ms DataYandexMdbKafkaCluster#log_flush_scheduler_interval_ms}
    */
    readonly logFlushSchedulerIntervalMs?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#log_preallocate DataYandexMdbKafkaCluster#log_preallocate}
    */
    readonly logPreallocate?: boolean | cdktf.IResolvable;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#log_retention_bytes DataYandexMdbKafkaCluster#log_retention_bytes}
    */
    readonly logRetentionBytes?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#log_retention_hours DataYandexMdbKafkaCluster#log_retention_hours}
    */
    readonly logRetentionHours?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#log_retention_minutes DataYandexMdbKafkaCluster#log_retention_minutes}
    */
    readonly logRetentionMinutes?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#log_retention_ms DataYandexMdbKafkaCluster#log_retention_ms}
    */
    readonly logRetentionMs?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#log_segment_bytes DataYandexMdbKafkaCluster#log_segment_bytes}
    */
    readonly logSegmentBytes?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#num_partitions DataYandexMdbKafkaCluster#num_partitions}
    */
    readonly numPartitions?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#socket_receive_buffer_bytes DataYandexMdbKafkaCluster#socket_receive_buffer_bytes}
    */
    readonly socketReceiveBufferBytes?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#socket_send_buffer_bytes DataYandexMdbKafkaCluster#socket_send_buffer_bytes}
    */
    readonly socketSendBufferBytes?: string;
}
export declare function dataYandexMdbKafkaClusterConfigKafkaKafkaConfigToTerraform(struct?: DataYandexMdbKafkaClusterConfigKafkaKafkaConfigOutputReference | DataYandexMdbKafkaClusterConfigKafkaKafkaConfig): any;
export declare class DataYandexMdbKafkaClusterConfigKafkaKafkaConfigOutputReference extends cdktf.ComplexObject {
    private isEmptyObject;
    /**
    * @param terraformResource The parent resource
    * @param terraformAttribute The attribute on the parent resource this class is referencing
    */
    constructor(terraformResource: cdktf.IInterpolatingParent, terraformAttribute: string);
    get internalValue(): DataYandexMdbKafkaClusterConfigKafkaKafkaConfig | undefined;
    set internalValue(value: DataYandexMdbKafkaClusterConfigKafkaKafkaConfig | undefined);
    private _autoCreateTopicsEnable?;
    get autoCreateTopicsEnable(): boolean | cdktf.IResolvable;
    set autoCreateTopicsEnable(value: boolean | cdktf.IResolvable);
    resetAutoCreateTopicsEnable(): void;
    get autoCreateTopicsEnableInput(): boolean | cdktf.IResolvable | undefined;
    private _compressionType?;
    get compressionType(): string;
    set compressionType(value: string);
    resetCompressionType(): void;
    get compressionTypeInput(): string | undefined;
    private _defaultReplicationFactor?;
    get defaultReplicationFactor(): string;
    set defaultReplicationFactor(value: string);
    resetDefaultReplicationFactor(): void;
    get defaultReplicationFactorInput(): string | undefined;
    private _logFlushIntervalMessages?;
    get logFlushIntervalMessages(): string;
    set logFlushIntervalMessages(value: string);
    resetLogFlushIntervalMessages(): void;
    get logFlushIntervalMessagesInput(): string | undefined;
    private _logFlushIntervalMs?;
    get logFlushIntervalMs(): string;
    set logFlushIntervalMs(value: string);
    resetLogFlushIntervalMs(): void;
    get logFlushIntervalMsInput(): string | undefined;
    private _logFlushSchedulerIntervalMs?;
    get logFlushSchedulerIntervalMs(): string;
    set logFlushSchedulerIntervalMs(value: string);
    resetLogFlushSchedulerIntervalMs(): void;
    get logFlushSchedulerIntervalMsInput(): string | undefined;
    private _logPreallocate?;
    get logPreallocate(): boolean | cdktf.IResolvable;
    set logPreallocate(value: boolean | cdktf.IResolvable);
    resetLogPreallocate(): void;
    get logPreallocateInput(): boolean | cdktf.IResolvable | undefined;
    private _logRetentionBytes?;
    get logRetentionBytes(): string;
    set logRetentionBytes(value: string);
    resetLogRetentionBytes(): void;
    get logRetentionBytesInput(): string | undefined;
    private _logRetentionHours?;
    get logRetentionHours(): string;
    set logRetentionHours(value: string);
    resetLogRetentionHours(): void;
    get logRetentionHoursInput(): string | undefined;
    private _logRetentionMinutes?;
    get logRetentionMinutes(): string;
    set logRetentionMinutes(value: string);
    resetLogRetentionMinutes(): void;
    get logRetentionMinutesInput(): string | undefined;
    private _logRetentionMs?;
    get logRetentionMs(): string;
    set logRetentionMs(value: string);
    resetLogRetentionMs(): void;
    get logRetentionMsInput(): string | undefined;
    private _logSegmentBytes?;
    get logSegmentBytes(): string;
    set logSegmentBytes(value: string);
    resetLogSegmentBytes(): void;
    get logSegmentBytesInput(): string | undefined;
    private _numPartitions?;
    get numPartitions(): string;
    set numPartitions(value: string);
    resetNumPartitions(): void;
    get numPartitionsInput(): string | undefined;
    private _socketReceiveBufferBytes?;
    get socketReceiveBufferBytes(): string;
    set socketReceiveBufferBytes(value: string);
    resetSocketReceiveBufferBytes(): void;
    get socketReceiveBufferBytesInput(): string | undefined;
    private _socketSendBufferBytes?;
    get socketSendBufferBytes(): string;
    set socketSendBufferBytes(value: string);
    resetSocketSendBufferBytes(): void;
    get socketSendBufferBytesInput(): string | undefined;
}
export interface DataYandexMdbKafkaClusterConfigKafkaResources {
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#disk_size DataYandexMdbKafkaCluster#disk_size}
    */
    readonly diskSize: number;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#disk_type_id DataYandexMdbKafkaCluster#disk_type_id}
    */
    readonly diskTypeId: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#resource_preset_id DataYandexMdbKafkaCluster#resource_preset_id}
    */
    readonly resourcePresetId: string;
}
export declare function dataYandexMdbKafkaClusterConfigKafkaResourcesToTerraform(struct?: DataYandexMdbKafkaClusterConfigKafkaResourcesOutputReference | DataYandexMdbKafkaClusterConfigKafkaResources): any;
export declare class DataYandexMdbKafkaClusterConfigKafkaResourcesOutputReference extends cdktf.ComplexObject {
    private isEmptyObject;
    /**
    * @param terraformResource The parent resource
    * @param terraformAttribute The attribute on the parent resource this class is referencing
    */
    constructor(terraformResource: cdktf.IInterpolatingParent, terraformAttribute: string);
    get internalValue(): DataYandexMdbKafkaClusterConfigKafkaResources | undefined;
    set internalValue(value: DataYandexMdbKafkaClusterConfigKafkaResources | undefined);
    private _diskSize?;
    get diskSize(): number;
    set diskSize(value: number);
    get diskSizeInput(): number | undefined;
    private _diskTypeId?;
    get diskTypeId(): string;
    set diskTypeId(value: string);
    get diskTypeIdInput(): string | undefined;
    private _resourcePresetId?;
    get resourcePresetId(): string;
    set resourcePresetId(value: string);
    get resourcePresetIdInput(): string | undefined;
}
export interface DataYandexMdbKafkaClusterConfigKafka {
    /**
    * kafka_config block
    *
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#kafka_config DataYandexMdbKafkaCluster#kafka_config}
    */
    readonly kafkaConfig?: DataYandexMdbKafkaClusterConfigKafkaKafkaConfig;
    /**
    * resources block
    *
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#resources DataYandexMdbKafkaCluster#resources}
    */
    readonly resources: DataYandexMdbKafkaClusterConfigKafkaResources;
}
export declare function dataYandexMdbKafkaClusterConfigKafkaToTerraform(struct?: DataYandexMdbKafkaClusterConfigKafkaOutputReference | DataYandexMdbKafkaClusterConfigKafka): any;
export declare class DataYandexMdbKafkaClusterConfigKafkaOutputReference extends cdktf.ComplexObject {
    private isEmptyObject;
    /**
    * @param terraformResource The parent resource
    * @param terraformAttribute The attribute on the parent resource this class is referencing
    */
    constructor(terraformResource: cdktf.IInterpolatingParent, terraformAttribute: string);
    get internalValue(): DataYandexMdbKafkaClusterConfigKafka | undefined;
    set internalValue(value: DataYandexMdbKafkaClusterConfigKafka | undefined);
    private _kafkaConfig;
    get kafkaConfig(): DataYandexMdbKafkaClusterConfigKafkaKafkaConfigOutputReference;
    putKafkaConfig(value: DataYandexMdbKafkaClusterConfigKafkaKafkaConfig): void;
    resetKafkaConfig(): void;
    get kafkaConfigInput(): DataYandexMdbKafkaClusterConfigKafkaKafkaConfig | undefined;
    private _resources;
    get resources(): DataYandexMdbKafkaClusterConfigKafkaResourcesOutputReference;
    putResources(value: DataYandexMdbKafkaClusterConfigKafkaResources): void;
    get resourcesInput(): DataYandexMdbKafkaClusterConfigKafkaResources | undefined;
}
export interface DataYandexMdbKafkaClusterConfigZookeeperResources {
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#disk_size DataYandexMdbKafkaCluster#disk_size}
    */
    readonly diskSize?: number;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#disk_type_id DataYandexMdbKafkaCluster#disk_type_id}
    */
    readonly diskTypeId?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#resource_preset_id DataYandexMdbKafkaCluster#resource_preset_id}
    */
    readonly resourcePresetId?: string;
}
export declare function dataYandexMdbKafkaClusterConfigZookeeperResourcesToTerraform(struct?: DataYandexMdbKafkaClusterConfigZookeeperResourcesOutputReference | DataYandexMdbKafkaClusterConfigZookeeperResources): any;
export declare class DataYandexMdbKafkaClusterConfigZookeeperResourcesOutputReference extends cdktf.ComplexObject {
    private isEmptyObject;
    /**
    * @param terraformResource The parent resource
    * @param terraformAttribute The attribute on the parent resource this class is referencing
    */
    constructor(terraformResource: cdktf.IInterpolatingParent, terraformAttribute: string);
    get internalValue(): DataYandexMdbKafkaClusterConfigZookeeperResources | undefined;
    set internalValue(value: DataYandexMdbKafkaClusterConfigZookeeperResources | undefined);
    private _diskSize?;
    get diskSize(): number;
    set diskSize(value: number);
    resetDiskSize(): void;
    get diskSizeInput(): number | undefined;
    private _diskTypeId?;
    get diskTypeId(): string;
    set diskTypeId(value: string);
    resetDiskTypeId(): void;
    get diskTypeIdInput(): string | undefined;
    private _resourcePresetId?;
    get resourcePresetId(): string;
    set resourcePresetId(value: string);
    resetResourcePresetId(): void;
    get resourcePresetIdInput(): string | undefined;
}
export interface DataYandexMdbKafkaClusterConfigZookeeper {
    /**
    * resources block
    *
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#resources DataYandexMdbKafkaCluster#resources}
    */
    readonly resources?: DataYandexMdbKafkaClusterConfigZookeeperResources;
}
export declare function dataYandexMdbKafkaClusterConfigZookeeperToTerraform(struct?: DataYandexMdbKafkaClusterConfigZookeeperOutputReference | DataYandexMdbKafkaClusterConfigZookeeper): any;
export declare class DataYandexMdbKafkaClusterConfigZookeeperOutputReference extends cdktf.ComplexObject {
    private isEmptyObject;
    /**
    * @param terraformResource The parent resource
    * @param terraformAttribute The attribute on the parent resource this class is referencing
    */
    constructor(terraformResource: cdktf.IInterpolatingParent, terraformAttribute: string);
    get internalValue(): DataYandexMdbKafkaClusterConfigZookeeper | undefined;
    set internalValue(value: DataYandexMdbKafkaClusterConfigZookeeper | undefined);
    private _resources;
    get resources(): DataYandexMdbKafkaClusterConfigZookeeperResourcesOutputReference;
    putResources(value: DataYandexMdbKafkaClusterConfigZookeeperResources): void;
    resetResources(): void;
    get resourcesInput(): DataYandexMdbKafkaClusterConfigZookeeperResources | undefined;
}
export interface DataYandexMdbKafkaClusterConfigA {
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#assign_public_ip DataYandexMdbKafkaCluster#assign_public_ip}
    */
    readonly assignPublicIp?: boolean | cdktf.IResolvable;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#brokers_count DataYandexMdbKafkaCluster#brokers_count}
    */
    readonly brokersCount?: number;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#schema_registry DataYandexMdbKafkaCluster#schema_registry}
    */
    readonly schemaRegistry?: boolean | cdktf.IResolvable;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#unmanaged_topics DataYandexMdbKafkaCluster#unmanaged_topics}
    */
    readonly unmanagedTopics?: boolean | cdktf.IResolvable;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#version DataYandexMdbKafkaCluster#version}
    */
    readonly version: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#zones DataYandexMdbKafkaCluster#zones}
    */
    readonly zones: string[];
    /**
    * kafka block
    *
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#kafka DataYandexMdbKafkaCluster#kafka}
    */
    readonly kafka: DataYandexMdbKafkaClusterConfigKafka;
    /**
    * zookeeper block
    *
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#zookeeper DataYandexMdbKafkaCluster#zookeeper}
    */
    readonly zookeeper?: DataYandexMdbKafkaClusterConfigZookeeper;
}
export declare function dataYandexMdbKafkaClusterConfigAToTerraform(struct?: DataYandexMdbKafkaClusterConfigAOutputReference | DataYandexMdbKafkaClusterConfigA): any;
export declare class DataYandexMdbKafkaClusterConfigAOutputReference extends cdktf.ComplexObject {
    private isEmptyObject;
    /**
    * @param terraformResource The parent resource
    * @param terraformAttribute The attribute on the parent resource this class is referencing
    */
    constructor(terraformResource: cdktf.IInterpolatingParent, terraformAttribute: string);
    get internalValue(): DataYandexMdbKafkaClusterConfigA | undefined;
    set internalValue(value: DataYandexMdbKafkaClusterConfigA | undefined);
    private _assignPublicIp?;
    get assignPublicIp(): boolean | cdktf.IResolvable;
    set assignPublicIp(value: boolean | cdktf.IResolvable);
    resetAssignPublicIp(): void;
    get assignPublicIpInput(): boolean | cdktf.IResolvable | undefined;
    private _brokersCount?;
    get brokersCount(): number;
    set brokersCount(value: number);
    resetBrokersCount(): void;
    get brokersCountInput(): number | undefined;
    private _schemaRegistry?;
    get schemaRegistry(): boolean | cdktf.IResolvable;
    set schemaRegistry(value: boolean | cdktf.IResolvable);
    resetSchemaRegistry(): void;
    get schemaRegistryInput(): boolean | cdktf.IResolvable | undefined;
    private _unmanagedTopics?;
    get unmanagedTopics(): boolean | cdktf.IResolvable;
    set unmanagedTopics(value: boolean | cdktf.IResolvable);
    resetUnmanagedTopics(): void;
    get unmanagedTopicsInput(): boolean | cdktf.IResolvable | undefined;
    private _version?;
    get version(): string;
    set version(value: string);
    get versionInput(): string | undefined;
    private _zones?;
    get zones(): string[];
    set zones(value: string[]);
    get zonesInput(): string[] | undefined;
    private _kafka;
    get kafka(): DataYandexMdbKafkaClusterConfigKafkaOutputReference;
    putKafka(value: DataYandexMdbKafkaClusterConfigKafka): void;
    get kafkaInput(): DataYandexMdbKafkaClusterConfigKafka | undefined;
    private _zookeeper;
    get zookeeper(): DataYandexMdbKafkaClusterConfigZookeeperOutputReference;
    putZookeeper(value: DataYandexMdbKafkaClusterConfigZookeeper): void;
    resetZookeeper(): void;
    get zookeeperInput(): DataYandexMdbKafkaClusterConfigZookeeper | undefined;
}
export interface DataYandexMdbKafkaClusterTopicTopicConfig {
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#cleanup_policy DataYandexMdbKafkaCluster#cleanup_policy}
    */
    readonly cleanupPolicy?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#compression_type DataYandexMdbKafkaCluster#compression_type}
    */
    readonly compressionType?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#delete_retention_ms DataYandexMdbKafkaCluster#delete_retention_ms}
    */
    readonly deleteRetentionMs?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#file_delete_delay_ms DataYandexMdbKafkaCluster#file_delete_delay_ms}
    */
    readonly fileDeleteDelayMs?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#flush_messages DataYandexMdbKafkaCluster#flush_messages}
    */
    readonly flushMessages?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#flush_ms DataYandexMdbKafkaCluster#flush_ms}
    */
    readonly flushMs?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#max_message_bytes DataYandexMdbKafkaCluster#max_message_bytes}
    */
    readonly maxMessageBytes?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#min_compaction_lag_ms DataYandexMdbKafkaCluster#min_compaction_lag_ms}
    */
    readonly minCompactionLagMs?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#min_insync_replicas DataYandexMdbKafkaCluster#min_insync_replicas}
    */
    readonly minInsyncReplicas?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#preallocate DataYandexMdbKafkaCluster#preallocate}
    */
    readonly preallocate?: boolean | cdktf.IResolvable;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#retention_bytes DataYandexMdbKafkaCluster#retention_bytes}
    */
    readonly retentionBytes?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#retention_ms DataYandexMdbKafkaCluster#retention_ms}
    */
    readonly retentionMs?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#segment_bytes DataYandexMdbKafkaCluster#segment_bytes}
    */
    readonly segmentBytes?: string;
}
export declare function dataYandexMdbKafkaClusterTopicTopicConfigToTerraform(struct?: DataYandexMdbKafkaClusterTopicTopicConfigOutputReference | DataYandexMdbKafkaClusterTopicTopicConfig): any;
export declare class DataYandexMdbKafkaClusterTopicTopicConfigOutputReference extends cdktf.ComplexObject {
    private isEmptyObject;
    /**
    * @param terraformResource The parent resource
    * @param terraformAttribute The attribute on the parent resource this class is referencing
    */
    constructor(terraformResource: cdktf.IInterpolatingParent, terraformAttribute: string);
    get internalValue(): DataYandexMdbKafkaClusterTopicTopicConfig | undefined;
    set internalValue(value: DataYandexMdbKafkaClusterTopicTopicConfig | undefined);
    private _cleanupPolicy?;
    get cleanupPolicy(): string;
    set cleanupPolicy(value: string);
    resetCleanupPolicy(): void;
    get cleanupPolicyInput(): string | undefined;
    private _compressionType?;
    get compressionType(): string;
    set compressionType(value: string);
    resetCompressionType(): void;
    get compressionTypeInput(): string | undefined;
    private _deleteRetentionMs?;
    get deleteRetentionMs(): string;
    set deleteRetentionMs(value: string);
    resetDeleteRetentionMs(): void;
    get deleteRetentionMsInput(): string | undefined;
    private _fileDeleteDelayMs?;
    get fileDeleteDelayMs(): string;
    set fileDeleteDelayMs(value: string);
    resetFileDeleteDelayMs(): void;
    get fileDeleteDelayMsInput(): string | undefined;
    private _flushMessages?;
    get flushMessages(): string;
    set flushMessages(value: string);
    resetFlushMessages(): void;
    get flushMessagesInput(): string | undefined;
    private _flushMs?;
    get flushMs(): string;
    set flushMs(value: string);
    resetFlushMs(): void;
    get flushMsInput(): string | undefined;
    private _maxMessageBytes?;
    get maxMessageBytes(): string;
    set maxMessageBytes(value: string);
    resetMaxMessageBytes(): void;
    get maxMessageBytesInput(): string | undefined;
    private _minCompactionLagMs?;
    get minCompactionLagMs(): string;
    set minCompactionLagMs(value: string);
    resetMinCompactionLagMs(): void;
    get minCompactionLagMsInput(): string | undefined;
    private _minInsyncReplicas?;
    get minInsyncReplicas(): string;
    set minInsyncReplicas(value: string);
    resetMinInsyncReplicas(): void;
    get minInsyncReplicasInput(): string | undefined;
    private _preallocate?;
    get preallocate(): boolean | cdktf.IResolvable;
    set preallocate(value: boolean | cdktf.IResolvable);
    resetPreallocate(): void;
    get preallocateInput(): boolean | cdktf.IResolvable | undefined;
    private _retentionBytes?;
    get retentionBytes(): string;
    set retentionBytes(value: string);
    resetRetentionBytes(): void;
    get retentionBytesInput(): string | undefined;
    private _retentionMs?;
    get retentionMs(): string;
    set retentionMs(value: string);
    resetRetentionMs(): void;
    get retentionMsInput(): string | undefined;
    private _segmentBytes?;
    get segmentBytes(): string;
    set segmentBytes(value: string);
    resetSegmentBytes(): void;
    get segmentBytesInput(): string | undefined;
}
export interface DataYandexMdbKafkaClusterTopic {
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#cluster_id DataYandexMdbKafkaCluster#cluster_id}
    */
    readonly clusterId: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#name DataYandexMdbKafkaCluster#name}
    */
    readonly name: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#partitions DataYandexMdbKafkaCluster#partitions}
    */
    readonly partitions: number;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#replication_factor DataYandexMdbKafkaCluster#replication_factor}
    */
    readonly replicationFactor: number;
    /**
    * topic_config block
    *
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#topic_config DataYandexMdbKafkaCluster#topic_config}
    */
    readonly topicConfig?: DataYandexMdbKafkaClusterTopicTopicConfig;
}
export declare function dataYandexMdbKafkaClusterTopicToTerraform(struct?: DataYandexMdbKafkaClusterTopic | cdktf.IResolvable): any;
export declare class DataYandexMdbKafkaClusterTopicOutputReference extends cdktf.ComplexObject {
    private isEmptyObject;
    private resolvableValue?;
    /**
    * @param terraformResource The parent resource
    * @param terraformAttribute The attribute on the parent resource this class is referencing
    * @param complexObjectIndex the index of this item in the list
    * @param complexObjectIsFromSet whether the list is wrapping a set (will add tolist() to be able to access an item via an index)
    */
    constructor(terraformResource: cdktf.IInterpolatingParent, terraformAttribute: string, complexObjectIndex: number, complexObjectIsFromSet: boolean);
    get internalValue(): DataYandexMdbKafkaClusterTopic | cdktf.IResolvable | undefined;
    set internalValue(value: DataYandexMdbKafkaClusterTopic | cdktf.IResolvable | undefined);
    private _clusterId?;
    get clusterId(): string;
    set clusterId(value: string);
    get clusterIdInput(): string | undefined;
    private _name?;
    get name(): string;
    set name(value: string);
    get nameInput(): string | undefined;
    private _partitions?;
    get partitions(): number;
    set partitions(value: number);
    get partitionsInput(): number | undefined;
    private _replicationFactor?;
    get replicationFactor(): number;
    set replicationFactor(value: number);
    get replicationFactorInput(): number | undefined;
    private _topicConfig;
    get topicConfig(): DataYandexMdbKafkaClusterTopicTopicConfigOutputReference;
    putTopicConfig(value: DataYandexMdbKafkaClusterTopicTopicConfig): void;
    resetTopicConfig(): void;
    get topicConfigInput(): DataYandexMdbKafkaClusterTopicTopicConfig | undefined;
}
export declare class DataYandexMdbKafkaClusterTopicList extends cdktf.ComplexList {
    protected terraformResource: cdktf.IInterpolatingParent;
    protected terraformAttribute: string;
    protected wrapsSet: boolean;
    internalValue?: DataYandexMdbKafkaClusterTopic[] | cdktf.IResolvable;
    /**
    * @param terraformResource The parent resource
    * @param terraformAttribute The attribute on the parent resource this class is referencing
    * @param wrapsSet whether the list is wrapping a set (will add tolist() to be able to access an item via an index)
    */
    constructor(terraformResource: cdktf.IInterpolatingParent, terraformAttribute: string, wrapsSet: boolean);
    /**
    * @param index the index of the item to return
    */
    get(index: number): DataYandexMdbKafkaClusterTopicOutputReference;
}
export interface DataYandexMdbKafkaClusterUserPermission {
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#role DataYandexMdbKafkaCluster#role}
    */
    readonly role: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#topic_name DataYandexMdbKafkaCluster#topic_name}
    */
    readonly topicName: string;
}
export declare function dataYandexMdbKafkaClusterUserPermissionToTerraform(struct?: DataYandexMdbKafkaClusterUserPermission | cdktf.IResolvable): any;
export declare class DataYandexMdbKafkaClusterUserPermissionOutputReference extends cdktf.ComplexObject {
    private isEmptyObject;
    private resolvableValue?;
    /**
    * @param terraformResource The parent resource
    * @param terraformAttribute The attribute on the parent resource this class is referencing
    * @param complexObjectIndex the index of this item in the list
    * @param complexObjectIsFromSet whether the list is wrapping a set (will add tolist() to be able to access an item via an index)
    */
    constructor(terraformResource: cdktf.IInterpolatingParent, terraformAttribute: string, complexObjectIndex: number, complexObjectIsFromSet: boolean);
    get internalValue(): DataYandexMdbKafkaClusterUserPermission | cdktf.IResolvable | undefined;
    set internalValue(value: DataYandexMdbKafkaClusterUserPermission | cdktf.IResolvable | undefined);
    private _role?;
    get role(): string;
    set role(value: string);
    get roleInput(): string | undefined;
    private _topicName?;
    get topicName(): string;
    set topicName(value: string);
    get topicNameInput(): string | undefined;
}
export declare class DataYandexMdbKafkaClusterUserPermissionList extends cdktf.ComplexList {
    protected terraformResource: cdktf.IInterpolatingParent;
    protected terraformAttribute: string;
    protected wrapsSet: boolean;
    internalValue?: DataYandexMdbKafkaClusterUserPermission[] | cdktf.IResolvable;
    /**
    * @param terraformResource The parent resource
    * @param terraformAttribute The attribute on the parent resource this class is referencing
    * @param wrapsSet whether the list is wrapping a set (will add tolist() to be able to access an item via an index)
    */
    constructor(terraformResource: cdktf.IInterpolatingParent, terraformAttribute: string, wrapsSet: boolean);
    /**
    * @param index the index of the item to return
    */
    get(index: number): DataYandexMdbKafkaClusterUserPermissionOutputReference;
}
export interface DataYandexMdbKafkaClusterUser {
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#name DataYandexMdbKafkaCluster#name}
    */
    readonly name: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#password DataYandexMdbKafkaCluster#password}
    */
    readonly password: string;
    /**
    * permission block
    *
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster#permission DataYandexMdbKafkaCluster#permission}
    */
    readonly permission?: DataYandexMdbKafkaClusterUserPermission[] | cdktf.IResolvable;
}
export declare function dataYandexMdbKafkaClusterUserToTerraform(struct?: DataYandexMdbKafkaClusterUser | cdktf.IResolvable): any;
export declare class DataYandexMdbKafkaClusterUserOutputReference extends cdktf.ComplexObject {
    private isEmptyObject;
    private resolvableValue?;
    /**
    * @param terraformResource The parent resource
    * @param terraformAttribute The attribute on the parent resource this class is referencing
    * @param complexObjectIndex the index of this item in the list
    * @param complexObjectIsFromSet whether the list is wrapping a set (will add tolist() to be able to access an item via an index)
    */
    constructor(terraformResource: cdktf.IInterpolatingParent, terraformAttribute: string, complexObjectIndex: number, complexObjectIsFromSet: boolean);
    get internalValue(): DataYandexMdbKafkaClusterUser | cdktf.IResolvable | undefined;
    set internalValue(value: DataYandexMdbKafkaClusterUser | cdktf.IResolvable | undefined);
    private _name?;
    get name(): string;
    set name(value: string);
    get nameInput(): string | undefined;
    private _password?;
    get password(): string;
    set password(value: string);
    get passwordInput(): string | undefined;
    private _permission;
    get permission(): DataYandexMdbKafkaClusterUserPermissionList;
    putPermission(value: DataYandexMdbKafkaClusterUserPermission[] | cdktf.IResolvable): void;
    resetPermission(): void;
    get permissionInput(): cdktf.IResolvable | DataYandexMdbKafkaClusterUserPermission[] | undefined;
}
export declare class DataYandexMdbKafkaClusterUserList extends cdktf.ComplexList {
    protected terraformResource: cdktf.IInterpolatingParent;
    protected terraformAttribute: string;
    protected wrapsSet: boolean;
    internalValue?: DataYandexMdbKafkaClusterUser[] | cdktf.IResolvable;
    /**
    * @param terraformResource The parent resource
    * @param terraformAttribute The attribute on the parent resource this class is referencing
    * @param wrapsSet whether the list is wrapping a set (will add tolist() to be able to access an item via an index)
    */
    constructor(terraformResource: cdktf.IInterpolatingParent, terraformAttribute: string, wrapsSet: boolean);
    /**
    * @param index the index of the item to return
    */
    get(index: number): DataYandexMdbKafkaClusterUserOutputReference;
}
/**
* Represents a {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster yandex_mdb_kafka_cluster}
*/
export declare class DataYandexMdbKafkaCluster extends cdktf.TerraformDataSource {
    static readonly tfResourceType = "yandex_mdb_kafka_cluster";
    /**
    * Create a new {@link https://www.terraform.io/docs/providers/yandex/d/mdb_kafka_cluster yandex_mdb_kafka_cluster} Data Source
    *
    * @param scope The scope in which to define this construct
    * @param id The scoped construct ID. Must be unique amongst siblings in the same scope
    * @param options DataYandexMdbKafkaClusterConfig = {}
    */
    constructor(scope: Construct, id: string, config?: DataYandexMdbKafkaClusterConfig);
    private _clusterId?;
    get clusterId(): string;
    set clusterId(value: string);
    resetClusterId(): void;
    get clusterIdInput(): string | undefined;
    get createdAt(): string;
    private _deletionProtection?;
    get deletionProtection(): boolean | cdktf.IResolvable;
    set deletionProtection(value: boolean | cdktf.IResolvable);
    resetDeletionProtection(): void;
    get deletionProtectionInput(): boolean | cdktf.IResolvable | undefined;
    get description(): string;
    get environment(): string;
    private _folderId?;
    get folderId(): string;
    set folderId(value: string);
    resetFolderId(): void;
    get folderIdInput(): string | undefined;
    get health(): string;
    private _host;
    get host(): DataYandexMdbKafkaClusterHostList;
    get hostGroupIds(): string[];
    private _id?;
    get id(): string;
    set id(value: string);
    resetId(): void;
    get idInput(): string | undefined;
    private _labels;
    get labels(): cdktf.StringMap;
    private _maintenanceWindow;
    get maintenanceWindow(): DataYandexMdbKafkaClusterMaintenanceWindowList;
    private _name?;
    get name(): string;
    set name(value: string);
    resetName(): void;
    get nameInput(): string | undefined;
    get networkId(): string;
    get securityGroupIds(): string[];
    get status(): string;
    private _subnetIds?;
    get subnetIds(): string[];
    set subnetIds(value: string[]);
    resetSubnetIds(): void;
    get subnetIdsInput(): string[] | undefined;
    private _config;
    get config(): DataYandexMdbKafkaClusterConfigAOutputReference;
    putConfig(value: DataYandexMdbKafkaClusterConfigA): void;
    resetConfig(): void;
    get configInput(): DataYandexMdbKafkaClusterConfigA | undefined;
    private _topic;
    get topic(): DataYandexMdbKafkaClusterTopicList;
    putTopic(value: DataYandexMdbKafkaClusterTopic[] | cdktf.IResolvable): void;
    resetTopic(): void;
    get topicInput(): cdktf.IResolvable | DataYandexMdbKafkaClusterTopic[] | undefined;
    private _user;
    get user(): DataYandexMdbKafkaClusterUserList;
    putUser(value: DataYandexMdbKafkaClusterUser[] | cdktf.IResolvable): void;
    resetUser(): void;
    get userInput(): cdktf.IResolvable | DataYandexMdbKafkaClusterUser[] | undefined;
    protected synthesizeAttributes(): {
        [name: string]: any;
    };
}
