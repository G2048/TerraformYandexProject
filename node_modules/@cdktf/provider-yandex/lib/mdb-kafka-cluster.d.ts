import { Construct } from 'constructs';
import * as cdktf from 'cdktf';
export interface MdbKafkaClusterConfig extends cdktf.TerraformMetaArguments {
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#deletion_protection MdbKafkaCluster#deletion_protection}
    */
    readonly deletionProtection?: boolean | cdktf.IResolvable;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#description MdbKafkaCluster#description}
    */
    readonly description?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#environment MdbKafkaCluster#environment}
    */
    readonly environment?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#folder_id MdbKafkaCluster#folder_id}
    */
    readonly folderId?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#host_group_ids MdbKafkaCluster#host_group_ids}
    */
    readonly hostGroupIds?: string[];
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#id MdbKafkaCluster#id}
    *
    * Please be aware that the id field is automatically added to all resources in Terraform providers using a Terraform provider SDK version below 2.
    * If you experience problems setting this value it might not be settable. Please take a look at the provider documentation to ensure it should be settable.
    */
    readonly id?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#labels MdbKafkaCluster#labels}
    */
    readonly labels?: {
        [key: string]: string;
    };
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#name MdbKafkaCluster#name}
    */
    readonly name: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#network_id MdbKafkaCluster#network_id}
    */
    readonly networkId: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#security_group_ids MdbKafkaCluster#security_group_ids}
    */
    readonly securityGroupIds?: string[];
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#subnet_ids MdbKafkaCluster#subnet_ids}
    */
    readonly subnetIds?: string[];
    /**
    * config block
    *
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#config MdbKafkaCluster#config}
    */
    readonly config: MdbKafkaClusterConfigA;
    /**
    * maintenance_window block
    *
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#maintenance_window MdbKafkaCluster#maintenance_window}
    */
    readonly maintenanceWindow?: MdbKafkaClusterMaintenanceWindow;
    /**
    * timeouts block
    *
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#timeouts MdbKafkaCluster#timeouts}
    */
    readonly timeouts?: MdbKafkaClusterTimeouts;
    /**
    * topic block
    *
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#topic MdbKafkaCluster#topic}
    */
    readonly topic?: MdbKafkaClusterTopic[] | cdktf.IResolvable;
    /**
    * user block
    *
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#user MdbKafkaCluster#user}
    */
    readonly user?: MdbKafkaClusterUser[] | cdktf.IResolvable;
}
export interface MdbKafkaClusterHost {
}
export declare function mdbKafkaClusterHostToTerraform(struct?: MdbKafkaClusterHost): any;
export declare class MdbKafkaClusterHostOutputReference extends cdktf.ComplexObject {
    private isEmptyObject;
    /**
    * @param terraformResource The parent resource
    * @param terraformAttribute The attribute on the parent resource this class is referencing
    * @param complexObjectIndex the index of this item in the list
    * @param complexObjectIsFromSet whether the list is wrapping a set (will add tolist() to be able to access an item via an index)
    */
    constructor(terraformResource: cdktf.IInterpolatingParent, terraformAttribute: string, complexObjectIndex: number, complexObjectIsFromSet: boolean);
    get internalValue(): MdbKafkaClusterHost | undefined;
    set internalValue(value: MdbKafkaClusterHost | undefined);
    get assignPublicIp(): cdktf.IResolvable;
    get health(): string;
    get name(): string;
    get role(): string;
    get subnetId(): string;
    get zoneId(): string;
}
export declare class MdbKafkaClusterHostList extends cdktf.ComplexList {
    protected terraformResource: cdktf.IInterpolatingParent;
    protected terraformAttribute: string;
    protected wrapsSet: boolean;
    /**
    * @param terraformResource The parent resource
    * @param terraformAttribute The attribute on the parent resource this class is referencing
    * @param wrapsSet whether the list is wrapping a set (will add tolist() to be able to access an item via an index)
    */
    constructor(terraformResource: cdktf.IInterpolatingParent, terraformAttribute: string, wrapsSet: boolean);
    /**
    * @param index the index of the item to return
    */
    get(index: number): MdbKafkaClusterHostOutputReference;
}
export interface MdbKafkaClusterConfigKafkaKafkaConfig {
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#auto_create_topics_enable MdbKafkaCluster#auto_create_topics_enable}
    */
    readonly autoCreateTopicsEnable?: boolean | cdktf.IResolvable;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#compression_type MdbKafkaCluster#compression_type}
    */
    readonly compressionType?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#default_replication_factor MdbKafkaCluster#default_replication_factor}
    */
    readonly defaultReplicationFactor?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#log_flush_interval_messages MdbKafkaCluster#log_flush_interval_messages}
    */
    readonly logFlushIntervalMessages?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#log_flush_interval_ms MdbKafkaCluster#log_flush_interval_ms}
    */
    readonly logFlushIntervalMs?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#log_flush_scheduler_interval_ms MdbKafkaCluster#log_flush_scheduler_interval_ms}
    */
    readonly logFlushSchedulerIntervalMs?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#log_preallocate MdbKafkaCluster#log_preallocate}
    */
    readonly logPreallocate?: boolean | cdktf.IResolvable;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#log_retention_bytes MdbKafkaCluster#log_retention_bytes}
    */
    readonly logRetentionBytes?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#log_retention_hours MdbKafkaCluster#log_retention_hours}
    */
    readonly logRetentionHours?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#log_retention_minutes MdbKafkaCluster#log_retention_minutes}
    */
    readonly logRetentionMinutes?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#log_retention_ms MdbKafkaCluster#log_retention_ms}
    */
    readonly logRetentionMs?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#log_segment_bytes MdbKafkaCluster#log_segment_bytes}
    */
    readonly logSegmentBytes?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#num_partitions MdbKafkaCluster#num_partitions}
    */
    readonly numPartitions?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#socket_receive_buffer_bytes MdbKafkaCluster#socket_receive_buffer_bytes}
    */
    readonly socketReceiveBufferBytes?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#socket_send_buffer_bytes MdbKafkaCluster#socket_send_buffer_bytes}
    */
    readonly socketSendBufferBytes?: string;
}
export declare function mdbKafkaClusterConfigKafkaKafkaConfigToTerraform(struct?: MdbKafkaClusterConfigKafkaKafkaConfigOutputReference | MdbKafkaClusterConfigKafkaKafkaConfig): any;
export declare class MdbKafkaClusterConfigKafkaKafkaConfigOutputReference extends cdktf.ComplexObject {
    private isEmptyObject;
    /**
    * @param terraformResource The parent resource
    * @param terraformAttribute The attribute on the parent resource this class is referencing
    */
    constructor(terraformResource: cdktf.IInterpolatingParent, terraformAttribute: string);
    get internalValue(): MdbKafkaClusterConfigKafkaKafkaConfig | undefined;
    set internalValue(value: MdbKafkaClusterConfigKafkaKafkaConfig | undefined);
    private _autoCreateTopicsEnable?;
    get autoCreateTopicsEnable(): boolean | cdktf.IResolvable;
    set autoCreateTopicsEnable(value: boolean | cdktf.IResolvable);
    resetAutoCreateTopicsEnable(): void;
    get autoCreateTopicsEnableInput(): boolean | cdktf.IResolvable | undefined;
    private _compressionType?;
    get compressionType(): string;
    set compressionType(value: string);
    resetCompressionType(): void;
    get compressionTypeInput(): string | undefined;
    private _defaultReplicationFactor?;
    get defaultReplicationFactor(): string;
    set defaultReplicationFactor(value: string);
    resetDefaultReplicationFactor(): void;
    get defaultReplicationFactorInput(): string | undefined;
    private _logFlushIntervalMessages?;
    get logFlushIntervalMessages(): string;
    set logFlushIntervalMessages(value: string);
    resetLogFlushIntervalMessages(): void;
    get logFlushIntervalMessagesInput(): string | undefined;
    private _logFlushIntervalMs?;
    get logFlushIntervalMs(): string;
    set logFlushIntervalMs(value: string);
    resetLogFlushIntervalMs(): void;
    get logFlushIntervalMsInput(): string | undefined;
    private _logFlushSchedulerIntervalMs?;
    get logFlushSchedulerIntervalMs(): string;
    set logFlushSchedulerIntervalMs(value: string);
    resetLogFlushSchedulerIntervalMs(): void;
    get logFlushSchedulerIntervalMsInput(): string | undefined;
    private _logPreallocate?;
    get logPreallocate(): boolean | cdktf.IResolvable;
    set logPreallocate(value: boolean | cdktf.IResolvable);
    resetLogPreallocate(): void;
    get logPreallocateInput(): boolean | cdktf.IResolvable | undefined;
    private _logRetentionBytes?;
    get logRetentionBytes(): string;
    set logRetentionBytes(value: string);
    resetLogRetentionBytes(): void;
    get logRetentionBytesInput(): string | undefined;
    private _logRetentionHours?;
    get logRetentionHours(): string;
    set logRetentionHours(value: string);
    resetLogRetentionHours(): void;
    get logRetentionHoursInput(): string | undefined;
    private _logRetentionMinutes?;
    get logRetentionMinutes(): string;
    set logRetentionMinutes(value: string);
    resetLogRetentionMinutes(): void;
    get logRetentionMinutesInput(): string | undefined;
    private _logRetentionMs?;
    get logRetentionMs(): string;
    set logRetentionMs(value: string);
    resetLogRetentionMs(): void;
    get logRetentionMsInput(): string | undefined;
    private _logSegmentBytes?;
    get logSegmentBytes(): string;
    set logSegmentBytes(value: string);
    resetLogSegmentBytes(): void;
    get logSegmentBytesInput(): string | undefined;
    private _numPartitions?;
    get numPartitions(): string;
    set numPartitions(value: string);
    resetNumPartitions(): void;
    get numPartitionsInput(): string | undefined;
    private _socketReceiveBufferBytes?;
    get socketReceiveBufferBytes(): string;
    set socketReceiveBufferBytes(value: string);
    resetSocketReceiveBufferBytes(): void;
    get socketReceiveBufferBytesInput(): string | undefined;
    private _socketSendBufferBytes?;
    get socketSendBufferBytes(): string;
    set socketSendBufferBytes(value: string);
    resetSocketSendBufferBytes(): void;
    get socketSendBufferBytesInput(): string | undefined;
}
export interface MdbKafkaClusterConfigKafkaResources {
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#disk_size MdbKafkaCluster#disk_size}
    */
    readonly diskSize: number;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#disk_type_id MdbKafkaCluster#disk_type_id}
    */
    readonly diskTypeId: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#resource_preset_id MdbKafkaCluster#resource_preset_id}
    */
    readonly resourcePresetId: string;
}
export declare function mdbKafkaClusterConfigKafkaResourcesToTerraform(struct?: MdbKafkaClusterConfigKafkaResourcesOutputReference | MdbKafkaClusterConfigKafkaResources): any;
export declare class MdbKafkaClusterConfigKafkaResourcesOutputReference extends cdktf.ComplexObject {
    private isEmptyObject;
    /**
    * @param terraformResource The parent resource
    * @param terraformAttribute The attribute on the parent resource this class is referencing
    */
    constructor(terraformResource: cdktf.IInterpolatingParent, terraformAttribute: string);
    get internalValue(): MdbKafkaClusterConfigKafkaResources | undefined;
    set internalValue(value: MdbKafkaClusterConfigKafkaResources | undefined);
    private _diskSize?;
    get diskSize(): number;
    set diskSize(value: number);
    get diskSizeInput(): number | undefined;
    private _diskTypeId?;
    get diskTypeId(): string;
    set diskTypeId(value: string);
    get diskTypeIdInput(): string | undefined;
    private _resourcePresetId?;
    get resourcePresetId(): string;
    set resourcePresetId(value: string);
    get resourcePresetIdInput(): string | undefined;
}
export interface MdbKafkaClusterConfigKafka {
    /**
    * kafka_config block
    *
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#kafka_config MdbKafkaCluster#kafka_config}
    */
    readonly kafkaConfig?: MdbKafkaClusterConfigKafkaKafkaConfig;
    /**
    * resources block
    *
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#resources MdbKafkaCluster#resources}
    */
    readonly resources: MdbKafkaClusterConfigKafkaResources;
}
export declare function mdbKafkaClusterConfigKafkaToTerraform(struct?: MdbKafkaClusterConfigKafkaOutputReference | MdbKafkaClusterConfigKafka): any;
export declare class MdbKafkaClusterConfigKafkaOutputReference extends cdktf.ComplexObject {
    private isEmptyObject;
    /**
    * @param terraformResource The parent resource
    * @param terraformAttribute The attribute on the parent resource this class is referencing
    */
    constructor(terraformResource: cdktf.IInterpolatingParent, terraformAttribute: string);
    get internalValue(): MdbKafkaClusterConfigKafka | undefined;
    set internalValue(value: MdbKafkaClusterConfigKafka | undefined);
    private _kafkaConfig;
    get kafkaConfig(): MdbKafkaClusterConfigKafkaKafkaConfigOutputReference;
    putKafkaConfig(value: MdbKafkaClusterConfigKafkaKafkaConfig): void;
    resetKafkaConfig(): void;
    get kafkaConfigInput(): MdbKafkaClusterConfigKafkaKafkaConfig | undefined;
    private _resources;
    get resources(): MdbKafkaClusterConfigKafkaResourcesOutputReference;
    putResources(value: MdbKafkaClusterConfigKafkaResources): void;
    get resourcesInput(): MdbKafkaClusterConfigKafkaResources | undefined;
}
export interface MdbKafkaClusterConfigZookeeperResources {
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#disk_size MdbKafkaCluster#disk_size}
    */
    readonly diskSize?: number;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#disk_type_id MdbKafkaCluster#disk_type_id}
    */
    readonly diskTypeId?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#resource_preset_id MdbKafkaCluster#resource_preset_id}
    */
    readonly resourcePresetId?: string;
}
export declare function mdbKafkaClusterConfigZookeeperResourcesToTerraform(struct?: MdbKafkaClusterConfigZookeeperResourcesOutputReference | MdbKafkaClusterConfigZookeeperResources): any;
export declare class MdbKafkaClusterConfigZookeeperResourcesOutputReference extends cdktf.ComplexObject {
    private isEmptyObject;
    /**
    * @param terraformResource The parent resource
    * @param terraformAttribute The attribute on the parent resource this class is referencing
    */
    constructor(terraformResource: cdktf.IInterpolatingParent, terraformAttribute: string);
    get internalValue(): MdbKafkaClusterConfigZookeeperResources | undefined;
    set internalValue(value: MdbKafkaClusterConfigZookeeperResources | undefined);
    private _diskSize?;
    get diskSize(): number;
    set diskSize(value: number);
    resetDiskSize(): void;
    get diskSizeInput(): number | undefined;
    private _diskTypeId?;
    get diskTypeId(): string;
    set diskTypeId(value: string);
    resetDiskTypeId(): void;
    get diskTypeIdInput(): string | undefined;
    private _resourcePresetId?;
    get resourcePresetId(): string;
    set resourcePresetId(value: string);
    resetResourcePresetId(): void;
    get resourcePresetIdInput(): string | undefined;
}
export interface MdbKafkaClusterConfigZookeeper {
    /**
    * resources block
    *
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#resources MdbKafkaCluster#resources}
    */
    readonly resources?: MdbKafkaClusterConfigZookeeperResources;
}
export declare function mdbKafkaClusterConfigZookeeperToTerraform(struct?: MdbKafkaClusterConfigZookeeperOutputReference | MdbKafkaClusterConfigZookeeper): any;
export declare class MdbKafkaClusterConfigZookeeperOutputReference extends cdktf.ComplexObject {
    private isEmptyObject;
    /**
    * @param terraformResource The parent resource
    * @param terraformAttribute The attribute on the parent resource this class is referencing
    */
    constructor(terraformResource: cdktf.IInterpolatingParent, terraformAttribute: string);
    get internalValue(): MdbKafkaClusterConfigZookeeper | undefined;
    set internalValue(value: MdbKafkaClusterConfigZookeeper | undefined);
    private _resources;
    get resources(): MdbKafkaClusterConfigZookeeperResourcesOutputReference;
    putResources(value: MdbKafkaClusterConfigZookeeperResources): void;
    resetResources(): void;
    get resourcesInput(): MdbKafkaClusterConfigZookeeperResources | undefined;
}
export interface MdbKafkaClusterConfigA {
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#assign_public_ip MdbKafkaCluster#assign_public_ip}
    */
    readonly assignPublicIp?: boolean | cdktf.IResolvable;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#brokers_count MdbKafkaCluster#brokers_count}
    */
    readonly brokersCount?: number;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#schema_registry MdbKafkaCluster#schema_registry}
    */
    readonly schemaRegistry?: boolean | cdktf.IResolvable;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#unmanaged_topics MdbKafkaCluster#unmanaged_topics}
    */
    readonly unmanagedTopics?: boolean | cdktf.IResolvable;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#version MdbKafkaCluster#version}
    */
    readonly version: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#zones MdbKafkaCluster#zones}
    */
    readonly zones: string[];
    /**
    * kafka block
    *
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#kafka MdbKafkaCluster#kafka}
    */
    readonly kafka: MdbKafkaClusterConfigKafka;
    /**
    * zookeeper block
    *
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#zookeeper MdbKafkaCluster#zookeeper}
    */
    readonly zookeeper?: MdbKafkaClusterConfigZookeeper;
}
export declare function mdbKafkaClusterConfigAToTerraform(struct?: MdbKafkaClusterConfigAOutputReference | MdbKafkaClusterConfigA): any;
export declare class MdbKafkaClusterConfigAOutputReference extends cdktf.ComplexObject {
    private isEmptyObject;
    /**
    * @param terraformResource The parent resource
    * @param terraformAttribute The attribute on the parent resource this class is referencing
    */
    constructor(terraformResource: cdktf.IInterpolatingParent, terraformAttribute: string);
    get internalValue(): MdbKafkaClusterConfigA | undefined;
    set internalValue(value: MdbKafkaClusterConfigA | undefined);
    private _assignPublicIp?;
    get assignPublicIp(): boolean | cdktf.IResolvable;
    set assignPublicIp(value: boolean | cdktf.IResolvable);
    resetAssignPublicIp(): void;
    get assignPublicIpInput(): boolean | cdktf.IResolvable | undefined;
    private _brokersCount?;
    get brokersCount(): number;
    set brokersCount(value: number);
    resetBrokersCount(): void;
    get brokersCountInput(): number | undefined;
    private _schemaRegistry?;
    get schemaRegistry(): boolean | cdktf.IResolvable;
    set schemaRegistry(value: boolean | cdktf.IResolvable);
    resetSchemaRegistry(): void;
    get schemaRegistryInput(): boolean | cdktf.IResolvable | undefined;
    private _unmanagedTopics?;
    get unmanagedTopics(): boolean | cdktf.IResolvable;
    set unmanagedTopics(value: boolean | cdktf.IResolvable);
    resetUnmanagedTopics(): void;
    get unmanagedTopicsInput(): boolean | cdktf.IResolvable | undefined;
    private _version?;
    get version(): string;
    set version(value: string);
    get versionInput(): string | undefined;
    private _zones?;
    get zones(): string[];
    set zones(value: string[]);
    get zonesInput(): string[] | undefined;
    private _kafka;
    get kafka(): MdbKafkaClusterConfigKafkaOutputReference;
    putKafka(value: MdbKafkaClusterConfigKafka): void;
    get kafkaInput(): MdbKafkaClusterConfigKafka | undefined;
    private _zookeeper;
    get zookeeper(): MdbKafkaClusterConfigZookeeperOutputReference;
    putZookeeper(value: MdbKafkaClusterConfigZookeeper): void;
    resetZookeeper(): void;
    get zookeeperInput(): MdbKafkaClusterConfigZookeeper | undefined;
}
export interface MdbKafkaClusterMaintenanceWindow {
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#day MdbKafkaCluster#day}
    */
    readonly day?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#hour MdbKafkaCluster#hour}
    */
    readonly hour?: number;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#type MdbKafkaCluster#type}
    */
    readonly type: string;
}
export declare function mdbKafkaClusterMaintenanceWindowToTerraform(struct?: MdbKafkaClusterMaintenanceWindowOutputReference | MdbKafkaClusterMaintenanceWindow): any;
export declare class MdbKafkaClusterMaintenanceWindowOutputReference extends cdktf.ComplexObject {
    private isEmptyObject;
    /**
    * @param terraformResource The parent resource
    * @param terraformAttribute The attribute on the parent resource this class is referencing
    */
    constructor(terraformResource: cdktf.IInterpolatingParent, terraformAttribute: string);
    get internalValue(): MdbKafkaClusterMaintenanceWindow | undefined;
    set internalValue(value: MdbKafkaClusterMaintenanceWindow | undefined);
    private _day?;
    get day(): string;
    set day(value: string);
    resetDay(): void;
    get dayInput(): string | undefined;
    private _hour?;
    get hour(): number;
    set hour(value: number);
    resetHour(): void;
    get hourInput(): number | undefined;
    private _type?;
    get type(): string;
    set type(value: string);
    get typeInput(): string | undefined;
}
export interface MdbKafkaClusterTimeouts {
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#create MdbKafkaCluster#create}
    */
    readonly create?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#delete MdbKafkaCluster#delete}
    */
    readonly delete?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#read MdbKafkaCluster#read}
    */
    readonly read?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#update MdbKafkaCluster#update}
    */
    readonly update?: string;
}
export declare function mdbKafkaClusterTimeoutsToTerraform(struct?: MdbKafkaClusterTimeoutsOutputReference | MdbKafkaClusterTimeouts | cdktf.IResolvable): any;
export declare class MdbKafkaClusterTimeoutsOutputReference extends cdktf.ComplexObject {
    private isEmptyObject;
    private resolvableValue?;
    /**
    * @param terraformResource The parent resource
    * @param terraformAttribute The attribute on the parent resource this class is referencing
    */
    constructor(terraformResource: cdktf.IInterpolatingParent, terraformAttribute: string);
    get internalValue(): MdbKafkaClusterTimeouts | cdktf.IResolvable | undefined;
    set internalValue(value: MdbKafkaClusterTimeouts | cdktf.IResolvable | undefined);
    private _create?;
    get create(): string;
    set create(value: string);
    resetCreate(): void;
    get createInput(): string | undefined;
    private _delete?;
    get delete(): string;
    set delete(value: string);
    resetDelete(): void;
    get deleteInput(): string | undefined;
    private _read?;
    get read(): string;
    set read(value: string);
    resetRead(): void;
    get readInput(): string | undefined;
    private _update?;
    get update(): string;
    set update(value: string);
    resetUpdate(): void;
    get updateInput(): string | undefined;
}
export interface MdbKafkaClusterTopicTopicConfig {
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#cleanup_policy MdbKafkaCluster#cleanup_policy}
    */
    readonly cleanupPolicy?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#compression_type MdbKafkaCluster#compression_type}
    */
    readonly compressionType?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#delete_retention_ms MdbKafkaCluster#delete_retention_ms}
    */
    readonly deleteRetentionMs?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#file_delete_delay_ms MdbKafkaCluster#file_delete_delay_ms}
    */
    readonly fileDeleteDelayMs?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#flush_messages MdbKafkaCluster#flush_messages}
    */
    readonly flushMessages?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#flush_ms MdbKafkaCluster#flush_ms}
    */
    readonly flushMs?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#max_message_bytes MdbKafkaCluster#max_message_bytes}
    */
    readonly maxMessageBytes?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#min_compaction_lag_ms MdbKafkaCluster#min_compaction_lag_ms}
    */
    readonly minCompactionLagMs?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#min_insync_replicas MdbKafkaCluster#min_insync_replicas}
    */
    readonly minInsyncReplicas?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#preallocate MdbKafkaCluster#preallocate}
    */
    readonly preallocate?: boolean | cdktf.IResolvable;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#retention_bytes MdbKafkaCluster#retention_bytes}
    */
    readonly retentionBytes?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#retention_ms MdbKafkaCluster#retention_ms}
    */
    readonly retentionMs?: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#segment_bytes MdbKafkaCluster#segment_bytes}
    */
    readonly segmentBytes?: string;
}
export declare function mdbKafkaClusterTopicTopicConfigToTerraform(struct?: MdbKafkaClusterTopicTopicConfigOutputReference | MdbKafkaClusterTopicTopicConfig): any;
export declare class MdbKafkaClusterTopicTopicConfigOutputReference extends cdktf.ComplexObject {
    private isEmptyObject;
    /**
    * @param terraformResource The parent resource
    * @param terraformAttribute The attribute on the parent resource this class is referencing
    */
    constructor(terraformResource: cdktf.IInterpolatingParent, terraformAttribute: string);
    get internalValue(): MdbKafkaClusterTopicTopicConfig | undefined;
    set internalValue(value: MdbKafkaClusterTopicTopicConfig | undefined);
    private _cleanupPolicy?;
    get cleanupPolicy(): string;
    set cleanupPolicy(value: string);
    resetCleanupPolicy(): void;
    get cleanupPolicyInput(): string | undefined;
    private _compressionType?;
    get compressionType(): string;
    set compressionType(value: string);
    resetCompressionType(): void;
    get compressionTypeInput(): string | undefined;
    private _deleteRetentionMs?;
    get deleteRetentionMs(): string;
    set deleteRetentionMs(value: string);
    resetDeleteRetentionMs(): void;
    get deleteRetentionMsInput(): string | undefined;
    private _fileDeleteDelayMs?;
    get fileDeleteDelayMs(): string;
    set fileDeleteDelayMs(value: string);
    resetFileDeleteDelayMs(): void;
    get fileDeleteDelayMsInput(): string | undefined;
    private _flushMessages?;
    get flushMessages(): string;
    set flushMessages(value: string);
    resetFlushMessages(): void;
    get flushMessagesInput(): string | undefined;
    private _flushMs?;
    get flushMs(): string;
    set flushMs(value: string);
    resetFlushMs(): void;
    get flushMsInput(): string | undefined;
    private _maxMessageBytes?;
    get maxMessageBytes(): string;
    set maxMessageBytes(value: string);
    resetMaxMessageBytes(): void;
    get maxMessageBytesInput(): string | undefined;
    private _minCompactionLagMs?;
    get minCompactionLagMs(): string;
    set minCompactionLagMs(value: string);
    resetMinCompactionLagMs(): void;
    get minCompactionLagMsInput(): string | undefined;
    private _minInsyncReplicas?;
    get minInsyncReplicas(): string;
    set minInsyncReplicas(value: string);
    resetMinInsyncReplicas(): void;
    get minInsyncReplicasInput(): string | undefined;
    private _preallocate?;
    get preallocate(): boolean | cdktf.IResolvable;
    set preallocate(value: boolean | cdktf.IResolvable);
    resetPreallocate(): void;
    get preallocateInput(): boolean | cdktf.IResolvable | undefined;
    private _retentionBytes?;
    get retentionBytes(): string;
    set retentionBytes(value: string);
    resetRetentionBytes(): void;
    get retentionBytesInput(): string | undefined;
    private _retentionMs?;
    get retentionMs(): string;
    set retentionMs(value: string);
    resetRetentionMs(): void;
    get retentionMsInput(): string | undefined;
    private _segmentBytes?;
    get segmentBytes(): string;
    set segmentBytes(value: string);
    resetSegmentBytes(): void;
    get segmentBytesInput(): string | undefined;
}
export interface MdbKafkaClusterTopic {
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#name MdbKafkaCluster#name}
    */
    readonly name: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#partitions MdbKafkaCluster#partitions}
    */
    readonly partitions: number;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#replication_factor MdbKafkaCluster#replication_factor}
    */
    readonly replicationFactor: number;
    /**
    * topic_config block
    *
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#topic_config MdbKafkaCluster#topic_config}
    */
    readonly topicConfig?: MdbKafkaClusterTopicTopicConfig;
}
export declare function mdbKafkaClusterTopicToTerraform(struct?: MdbKafkaClusterTopic | cdktf.IResolvable): any;
export declare class MdbKafkaClusterTopicOutputReference extends cdktf.ComplexObject {
    private isEmptyObject;
    private resolvableValue?;
    /**
    * @param terraformResource The parent resource
    * @param terraformAttribute The attribute on the parent resource this class is referencing
    * @param complexObjectIndex the index of this item in the list
    * @param complexObjectIsFromSet whether the list is wrapping a set (will add tolist() to be able to access an item via an index)
    */
    constructor(terraformResource: cdktf.IInterpolatingParent, terraformAttribute: string, complexObjectIndex: number, complexObjectIsFromSet: boolean);
    get internalValue(): MdbKafkaClusterTopic | cdktf.IResolvable | undefined;
    set internalValue(value: MdbKafkaClusterTopic | cdktf.IResolvable | undefined);
    private _name?;
    get name(): string;
    set name(value: string);
    get nameInput(): string | undefined;
    private _partitions?;
    get partitions(): number;
    set partitions(value: number);
    get partitionsInput(): number | undefined;
    private _replicationFactor?;
    get replicationFactor(): number;
    set replicationFactor(value: number);
    get replicationFactorInput(): number | undefined;
    private _topicConfig;
    get topicConfig(): MdbKafkaClusterTopicTopicConfigOutputReference;
    putTopicConfig(value: MdbKafkaClusterTopicTopicConfig): void;
    resetTopicConfig(): void;
    get topicConfigInput(): MdbKafkaClusterTopicTopicConfig | undefined;
}
export declare class MdbKafkaClusterTopicList extends cdktf.ComplexList {
    protected terraformResource: cdktf.IInterpolatingParent;
    protected terraformAttribute: string;
    protected wrapsSet: boolean;
    internalValue?: MdbKafkaClusterTopic[] | cdktf.IResolvable;
    /**
    * @param terraformResource The parent resource
    * @param terraformAttribute The attribute on the parent resource this class is referencing
    * @param wrapsSet whether the list is wrapping a set (will add tolist() to be able to access an item via an index)
    */
    constructor(terraformResource: cdktf.IInterpolatingParent, terraformAttribute: string, wrapsSet: boolean);
    /**
    * @param index the index of the item to return
    */
    get(index: number): MdbKafkaClusterTopicOutputReference;
}
export interface MdbKafkaClusterUserPermission {
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#role MdbKafkaCluster#role}
    */
    readonly role: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#topic_name MdbKafkaCluster#topic_name}
    */
    readonly topicName: string;
}
export declare function mdbKafkaClusterUserPermissionToTerraform(struct?: MdbKafkaClusterUserPermission | cdktf.IResolvable): any;
export declare class MdbKafkaClusterUserPermissionOutputReference extends cdktf.ComplexObject {
    private isEmptyObject;
    private resolvableValue?;
    /**
    * @param terraformResource The parent resource
    * @param terraformAttribute The attribute on the parent resource this class is referencing
    * @param complexObjectIndex the index of this item in the list
    * @param complexObjectIsFromSet whether the list is wrapping a set (will add tolist() to be able to access an item via an index)
    */
    constructor(terraformResource: cdktf.IInterpolatingParent, terraformAttribute: string, complexObjectIndex: number, complexObjectIsFromSet: boolean);
    get internalValue(): MdbKafkaClusterUserPermission | cdktf.IResolvable | undefined;
    set internalValue(value: MdbKafkaClusterUserPermission | cdktf.IResolvable | undefined);
    private _role?;
    get role(): string;
    set role(value: string);
    get roleInput(): string | undefined;
    private _topicName?;
    get topicName(): string;
    set topicName(value: string);
    get topicNameInput(): string | undefined;
}
export declare class MdbKafkaClusterUserPermissionList extends cdktf.ComplexList {
    protected terraformResource: cdktf.IInterpolatingParent;
    protected terraformAttribute: string;
    protected wrapsSet: boolean;
    internalValue?: MdbKafkaClusterUserPermission[] | cdktf.IResolvable;
    /**
    * @param terraformResource The parent resource
    * @param terraformAttribute The attribute on the parent resource this class is referencing
    * @param wrapsSet whether the list is wrapping a set (will add tolist() to be able to access an item via an index)
    */
    constructor(terraformResource: cdktf.IInterpolatingParent, terraformAttribute: string, wrapsSet: boolean);
    /**
    * @param index the index of the item to return
    */
    get(index: number): MdbKafkaClusterUserPermissionOutputReference;
}
export interface MdbKafkaClusterUser {
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#name MdbKafkaCluster#name}
    */
    readonly name: string;
    /**
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#password MdbKafkaCluster#password}
    */
    readonly password: string;
    /**
    * permission block
    *
    * Docs at Terraform Registry: {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster#permission MdbKafkaCluster#permission}
    */
    readonly permission?: MdbKafkaClusterUserPermission[] | cdktf.IResolvable;
}
export declare function mdbKafkaClusterUserToTerraform(struct?: MdbKafkaClusterUser | cdktf.IResolvable): any;
export declare class MdbKafkaClusterUserOutputReference extends cdktf.ComplexObject {
    private isEmptyObject;
    private resolvableValue?;
    /**
    * @param terraformResource The parent resource
    * @param terraformAttribute The attribute on the parent resource this class is referencing
    * @param complexObjectIndex the index of this item in the list
    * @param complexObjectIsFromSet whether the list is wrapping a set (will add tolist() to be able to access an item via an index)
    */
    constructor(terraformResource: cdktf.IInterpolatingParent, terraformAttribute: string, complexObjectIndex: number, complexObjectIsFromSet: boolean);
    get internalValue(): MdbKafkaClusterUser | cdktf.IResolvable | undefined;
    set internalValue(value: MdbKafkaClusterUser | cdktf.IResolvable | undefined);
    private _name?;
    get name(): string;
    set name(value: string);
    get nameInput(): string | undefined;
    private _password?;
    get password(): string;
    set password(value: string);
    get passwordInput(): string | undefined;
    private _permission;
    get permission(): MdbKafkaClusterUserPermissionList;
    putPermission(value: MdbKafkaClusterUserPermission[] | cdktf.IResolvable): void;
    resetPermission(): void;
    get permissionInput(): cdktf.IResolvable | MdbKafkaClusterUserPermission[] | undefined;
}
export declare class MdbKafkaClusterUserList extends cdktf.ComplexList {
    protected terraformResource: cdktf.IInterpolatingParent;
    protected terraformAttribute: string;
    protected wrapsSet: boolean;
    internalValue?: MdbKafkaClusterUser[] | cdktf.IResolvable;
    /**
    * @param terraformResource The parent resource
    * @param terraformAttribute The attribute on the parent resource this class is referencing
    * @param wrapsSet whether the list is wrapping a set (will add tolist() to be able to access an item via an index)
    */
    constructor(terraformResource: cdktf.IInterpolatingParent, terraformAttribute: string, wrapsSet: boolean);
    /**
    * @param index the index of the item to return
    */
    get(index: number): MdbKafkaClusterUserOutputReference;
}
/**
* Represents a {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster yandex_mdb_kafka_cluster}
*/
export declare class MdbKafkaCluster extends cdktf.TerraformResource {
    static readonly tfResourceType = "yandex_mdb_kafka_cluster";
    /**
    * Create a new {@link https://www.terraform.io/docs/providers/yandex/r/mdb_kafka_cluster yandex_mdb_kafka_cluster} Resource
    *
    * @param scope The scope in which to define this construct
    * @param id The scoped construct ID. Must be unique amongst siblings in the same scope
    * @param options MdbKafkaClusterConfig
    */
    constructor(scope: Construct, id: string, config: MdbKafkaClusterConfig);
    get createdAt(): string;
    private _deletionProtection?;
    get deletionProtection(): boolean | cdktf.IResolvable;
    set deletionProtection(value: boolean | cdktf.IResolvable);
    resetDeletionProtection(): void;
    get deletionProtectionInput(): boolean | cdktf.IResolvable | undefined;
    private _description?;
    get description(): string;
    set description(value: string);
    resetDescription(): void;
    get descriptionInput(): string | undefined;
    private _environment?;
    get environment(): string;
    set environment(value: string);
    resetEnvironment(): void;
    get environmentInput(): string | undefined;
    private _folderId?;
    get folderId(): string;
    set folderId(value: string);
    resetFolderId(): void;
    get folderIdInput(): string | undefined;
    get health(): string;
    private _host;
    get host(): MdbKafkaClusterHostList;
    private _hostGroupIds?;
    get hostGroupIds(): string[];
    set hostGroupIds(value: string[]);
    resetHostGroupIds(): void;
    get hostGroupIdsInput(): string[] | undefined;
    private _id?;
    get id(): string;
    set id(value: string);
    resetId(): void;
    get idInput(): string | undefined;
    private _labels?;
    get labels(): {
        [key: string]: string;
    };
    set labels(value: {
        [key: string]: string;
    });
    resetLabels(): void;
    get labelsInput(): {
        [key: string]: string;
    } | undefined;
    private _name?;
    get name(): string;
    set name(value: string);
    get nameInput(): string | undefined;
    private _networkId?;
    get networkId(): string;
    set networkId(value: string);
    get networkIdInput(): string | undefined;
    private _securityGroupIds?;
    get securityGroupIds(): string[];
    set securityGroupIds(value: string[]);
    resetSecurityGroupIds(): void;
    get securityGroupIdsInput(): string[] | undefined;
    get status(): string;
    private _subnetIds?;
    get subnetIds(): string[];
    set subnetIds(value: string[]);
    resetSubnetIds(): void;
    get subnetIdsInput(): string[] | undefined;
    private _config;
    get config(): MdbKafkaClusterConfigAOutputReference;
    putConfig(value: MdbKafkaClusterConfigA): void;
    get configInput(): MdbKafkaClusterConfigA | undefined;
    private _maintenanceWindow;
    get maintenanceWindow(): MdbKafkaClusterMaintenanceWindowOutputReference;
    putMaintenanceWindow(value: MdbKafkaClusterMaintenanceWindow): void;
    resetMaintenanceWindow(): void;
    get maintenanceWindowInput(): MdbKafkaClusterMaintenanceWindow | undefined;
    private _timeouts;
    get timeouts(): MdbKafkaClusterTimeoutsOutputReference;
    putTimeouts(value: MdbKafkaClusterTimeouts): void;
    resetTimeouts(): void;
    get timeoutsInput(): cdktf.IResolvable | MdbKafkaClusterTimeouts | undefined;
    private _topic;
    get topic(): MdbKafkaClusterTopicList;
    putTopic(value: MdbKafkaClusterTopic[] | cdktf.IResolvable): void;
    resetTopic(): void;
    get topicInput(): cdktf.IResolvable | MdbKafkaClusterTopic[] | undefined;
    private _user;
    get user(): MdbKafkaClusterUserList;
    putUser(value: MdbKafkaClusterUser[] | cdktf.IResolvable): void;
    resetUser(): void;
    get userInput(): cdktf.IResolvable | MdbKafkaClusterUser[] | undefined;
    protected synthesizeAttributes(): {
        [name: string]: any;
    };
}
